# AAAI-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/AAAI-2024-Papers/blob/main/sections/2024/main/machine_learning.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/AAAI-2024-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/AAAI-2024-Papers/blob/main/sections/2024/main/natural_language_processing.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Multiagent Systems

![Section Papers](https://img.shields.io/badge/Section%20Papers-39-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-soon-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-soon-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-soon-FF0000)

| :id: | **Title** | **Repo** | **Paper** | **Video** |
|------|-----------|:--------:|:---------:|:---------:|
| | [Improved Anonymous Multi-Agent Path Finding Algorithm](https://ojs.aaai.org/index.php/AAAI/article/view/29676) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29676/31156) | |
| | [Cautiously-Optimistic Knowledge Sharing for Cooperative Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29677) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29677/31157) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29677/31158) |
| | [Natural Strategic Ability in Stochastic Multi-Agent Systems](https://ojs.aaai.org/index.php/AAAI/article/view/29678) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29678/31159) | |
| | [On Alternating-Time Temporal Logic, Hyperproperties, and Strategy Sharing](https://ojs.aaai.org/index.php/AAAI/article/view/29679) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29679/31160) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29679/31161) |
| | [RGMComm: Return Gap Minimization via Discrete Communications in Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29680) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29680/31162) | |
| | [STAS: Spatial-Temporal Return Decomposition for Solving Sparse Rewards Problems in Multi-agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29681) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29681/31163) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29681/31164) |
| | [Learning Efficient and Robust Multi-Agent Communication via Graph Information Bottleneck](https://ojs.aaai.org/index.php/AAAI/article/view/29682) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29682/31165) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29682/31166) |
| | [Expressive Multi-Agent Communication via Identity-Aware Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29683) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29683/31167) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29683/31168) |
| | [Situation-Dependent Causal Influence-Based Cooperative Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29684) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29684/31169) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29684/31170) |
| | [Learning Multi-Object Positional Relationships via Emergent Communication](https://ojs.aaai.org/index.php/AAAI/article/view/29685) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29685/31171) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29685/31172) |
| | [Exact Algorithms and Lowerbounds for Multiagent Path Finding: Power of Treelike Topology](https://ojs.aaai.org/index.php/AAAI/article/view/29686) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29686/31173) | |
| | [The Irrelevance of Influencers: Information Diffusion with Re-Activation and Immunity Lasts Exponentially Long on Social Network Models](https://ojs.aaai.org/index.php/AAAI/article/view/29687) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29687/31174) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29687/31175) |
| | [Memory Asymmetry Creates Heteroclinic Orbits to Nash Equilibrium in Learning in Zero-Sum Games](https://ojs.aaai.org/index.php/AAAI/article/view/29688) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29688/31176) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29688/31177) |
| | [Factored Online Planning in Many-Agent POMDPs](https://ojs.aaai.org/index.php/AAAI/article/view/29689) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29689/31178) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29689/31179) |
| | [Foundations of Reactive Synthesis for Declarative Process Specifications](https://ojs.aaai.org/index.php/AAAI/article/view/29690) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29690/31180) | |
| | [Learning in Online Principal-Agent Interactions: The Power of Menus](https://ojs.aaai.org/index.php/AAAI/article/view/29691) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29691/31181) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29691/31182) |
| | [Stability of Multi-Agent Learning in Competitive Networks: Delaying the Onset of Chaos](https://ojs.aaai.org/index.php/AAAI/article/view/29692) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29692/31183) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29692/31184) |
| | [Settling Decentralized Multi-Agent Coordinated Exploration by Novelty Sharing](https://ojs.aaai.org/index.php/AAAI/article/view/29693) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29693/31185) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29693/31186) |
| | [Optimistic Value Instructors for Cooperative Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29694) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29694/31187) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29694/31188) |
| | [ConcaveQ: Non-monotonic Value Function Factorization via Concave Representations in Deep Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29695) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29695/31189) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29695/31190) |
| | [Transition-Informed Reinforcement Learning for Large-Scale Stackelberg Mean-Field Games](https://ojs.aaai.org/index.php/AAAI/article/view/29696) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29696/31191) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29696/31192) |
| | [Decentralized Gradient-Free Methods for Stochastic Non-smooth Non-convex Optimization](https://ojs.aaai.org/index.php/AAAI/article/view/29697) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29697/31193) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29697/31194) |
| | [Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29698) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29698/31195) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29698/31196) |
| | [TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy Gradient](https://ojs.aaai.org/index.php/AAAI/article/view/29699) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29699/31197) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29699/31198) |
| | [PMAC: Personalized Multi-Agent Communication](https://ojs.aaai.org/index.php/AAAI/article/view/29700) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29700/31199) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29700/31200) |
| | [Adaptive Anytime Multi-Agent Path Finding Using Bandit-Based Large Neighborhood Search](https://ojs.aaai.org/index.php/AAAI/article/view/29701) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29701/31201) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29701/31202) |
| | [Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents](https://ojs.aaai.org/index.php/AAAI/article/view/29702) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29702/31203) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29702/31204) |
| | [Decentralized Monte Carlo Tree Search for Partially Observable Multi-Agent Pathfinding](https://ojs.aaai.org/index.php/AAAI/article/view/29703) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29703/31205) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29703/31206) |
| | [Learn to Follow: Decentralized Lifelong Multi-Agent Pathfinding via Planning and Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29704) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29704/31207) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29704/31208) |
| | [What Makes Good Collaborative Views? Contrastive Mutual Information Maximization for Multi-Agent Perception](https://ojs.aaai.org/index.php/AAAI/article/view/29705) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29705/31209) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29705/31210) |
| | [Bidirectional Temporal Plan Graph: Enabling Switchable Passing Orders for More Efficient Multi-Agent Path Finding Plan Execution](https://ojs.aaai.org/index.php/AAAI/article/view/29706) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29706/31211) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29706/31212) |
| | [Large-Scale Multi-Robot Coverage Path Planning via Local Search](https://ojs.aaai.org/index.php/AAAI/article/view/29707) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29707/31213) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29707/31214) |
| | [Robust Communicative Multi-Agent Reinforcement Learning with Active Defense](https://ojs.aaai.org/index.php/AAAI/article/view/29708) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29708/31215) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29708/31216) |
| | [Leveraging Partial Symmetry for Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29709) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29709/31217) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29709/31218) |
| | [ProAgent: Building Proactive Cooperative Agents with Large Language Models](https://ojs.aaai.org/index.php/AAAI/article/view/29710) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29710/31219) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29710/31220) |
| | [Intrinsic Action Tendency Consistency for Cooperative Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29711) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29711/31221) | |
| | [Emergent Communication for Numerical Concepts Generalization](https://ojs.aaai.org/index.php/AAAI/article/view/29712) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29712/31222) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29712/31223) |
| | [Decomposing Temporal Equilibrium Strategy for Coordinated Distributed Multi-Agent Reinforcement Learning](https://ojs.aaai.org/index.php/AAAI/article/view/29713) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29713/31224) | [![YouVideo](https://img.shields.io/badge/Video-000000??&style=flat&logo=youtube&logoColor=white)](https://ojs.aaai.org/index.php/AAAI/article/view/29713/31225) |
| | [Balancing Humans and Machines: A Study on Integration Scale and Its Impact on Collaborative Performance](https://ojs.aaai.org/index.php/AAAI/article/view/29714) | :heavy_minus_sign: | [![ojs.aaai](https://img.shields.io/badge/pdf-ojs.aaai-1F6292.svg)](https://ojs.aaai.org/index.php/AAAI/article/view/29714/31226) | |
